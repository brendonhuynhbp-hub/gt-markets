{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCn5i6KJObidjaLF5mTc6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendonhuynhbp-hub/gt-markets/blob/main/notebooks/GoogleTrends_Financial_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# ENGINEERED DATASET BUILDER (Colab-friendly, robust paths)\n",
        "# - Mounts Google Drive\n",
        "# - Auto-detects project folder\n",
        "# - Finds latest RAW merged file (csv/parquet)\n",
        "# - Builds engineered features per-asset (no global dropna)\n",
        "# - Left-joins features, imputes only engineered cols\n",
        "# - Saves engineered parquet + csv\n",
        "# =========================================================\n",
        "\n",
        "# ---------- 0) Mount Drive ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- 1) Imports ----------\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ---------- 2) Locate project folder ----------\n",
        "CANDIDATE_PROJECT_DIRS = [\n",
        "    Path(\"/content/drive/MyDrive/gt-markets\"),\n",
        "    Path(\"/content/drive/Shareddrives/gt-markets\"),\n",
        "]\n",
        "PROJECT_DIR = next((p for p in CANDIDATE_PROJECT_DIRS if p.exists()), None)\n",
        "assert PROJECT_DIR is not None, \"Project directory not found. Ensure 'gt-markets' exists in MyDrive or a Shared Drive.\"\n",
        "\n",
        "DATA_DIR = PROJECT_DIR / \"data\" / \"processed\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
        "print(\"DATA_DIR:   \", DATA_DIR)\n",
        "\n",
        "# ---------- 3) Find latest RAW merged file (csv or parquet) ----------\n",
        "def _latest(patterns):\n",
        "    files = []\n",
        "    for pat in patterns:\n",
        "        files += list(DATA_DIR.glob(pat))\n",
        "    files = sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return files[0] if files else None\n",
        "\n",
        "RAW_FILE = _latest([\n",
        "    \"merged_financial_trends_data_*.parquet\",\n",
        "    \"merged_financial_trends_data_*.csv\",\n",
        "])\n",
        "\n",
        "assert RAW_FILE is not None, (\n",
        "    \"Could not find a raw merged file in processed/. \"\n",
        "    \"Expected something like 'merged_financial_trends_data_YYYY-MM-DD.csv' or .parquet\"\n",
        ")\n",
        "print(\"Using RAW_FILE:\", RAW_FILE.name)\n",
        "\n",
        "# Suffix for output filenames\n",
        "if RAW_FILE.suffix.lower() in (\".csv\", \".parquet\"):\n",
        "    stem = RAW_FILE.stem.replace(\"merged_financial_trends_data_\", \"\")\n",
        "else:\n",
        "    stem = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "OUT_PARQUET = DATA_DIR / f\"merged_financial_trends_engineered_{stem}.parquet\"\n",
        "OUT_CSV     = DATA_DIR / f\"merged_financial_trends_engineered_{stem}.csv\"\n",
        "\n",
        "# ---------- 4) Load raw merged dataset ----------\n",
        "def load_raw(path: Path) -> pd.DataFrame:\n",
        "    if path.suffix.lower() == \".parquet\":\n",
        "        df = pd.read_parquet(path)\n",
        "    else:\n",
        "        df = pd.read_csv(path)\n",
        "    assert \"Date\" in df.columns, \"Expected a 'Date' column in RAW merged file.\"\n",
        "    df = df.copy()\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.set_index(\"Date\").sort_index()\n",
        "\n",
        "    # Fill GT trend NaNs with 0 (legit for Google Trends)\n",
        "    trend_cols = [c for c in df.columns if \"trend\" in c.lower()]\n",
        "    if trend_cols:\n",
        "        bad = [c for c in trend_cols if df[c].isna().any()]\n",
        "        if bad:\n",
        "            print(f\"Filling NaN in trend cols with 0 (first 10 shown): {bad[:10]}\")\n",
        "            df[bad] = df[bad].fillna(0.0)\n",
        "    return df\n",
        "\n",
        "df0 = load_raw(RAW_FILE)\n",
        "\n",
        "# ---------- 5) Asset registry (edit if your column names differ) ----------\n",
        "ASSETS = [\n",
        "    {\"PAIR_ID\": \"GC=F\",      \"price_col\": \"GC=F Close\",      \"label\": \"Gold\"},\n",
        "    {\"PAIR_ID\": \"BTC-USD\",   \"price_col\": \"BTC-USD Close\",   \"label\": \"BTC\"},\n",
        "    {\"PAIR_ID\": \"CL=F\",      \"price_col\": \"CL=F Close\",      \"label\": \"Oil\"},\n",
        "    {\"PAIR_ID\": \"USDCNY=X\",  \"price_col\": \"USDCNY=X Close\",  \"label\": \"USDCNY\"},\n",
        "]\n",
        "for a in ASSETS:\n",
        "    assert a[\"price_col\"] in df0.columns, f\"Missing price column in RAW file: {a['price_col']}\"\n",
        "\n",
        "# ---------- 6) Indicator helpers (min_periods=1 keeps early rows) ----------\n",
        "def _safe_pct_change(s, periods=1):\n",
        "    r = s.pct_change(periods)\n",
        "    r = r.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "    return r.clip(-10.0, 10.0)\n",
        "\n",
        "def _rsi(close: pd.Series, window=14):\n",
        "    delta = close.diff()\n",
        "    up  = delta.clip(lower=0)\n",
        "    dn  = -delta.clip(upper=0)\n",
        "    roll_up = up.rolling(window, min_periods=1).mean()\n",
        "    roll_dn = dn.rolling(window, min_periods=1).mean()\n",
        "    rs  = (roll_up / roll_dn.replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def _bollinger(close: pd.Series, window=20, k=2.0):\n",
        "    ma  = close.rolling(window, min_periods=1).mean()\n",
        "    std = close.rolling(window, min_periods=1).std().fillna(0.0)\n",
        "    upper = ma + k * std\n",
        "    lower = ma - k * std\n",
        "    width = (upper - lower) / ma.replace(0, np.nan)\n",
        "    width = width.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "    return ma, upper, lower, width\n",
        "\n",
        "def _macd(close: pd.Series, fast=12, slow=26, signal=9):\n",
        "    ema_fast = close.ewm(span=fast, adjust=False, min_periods=1).mean()\n",
        "    ema_slow = close.ewm(span=slow, adjust=False, min_periods=1).mean()\n",
        "    macd    = ema_fast - ema_slow\n",
        "    signal_ = macd.ewm(span=signal, adjust=False, min_periods=1).mean()\n",
        "    hist    = macd - signal_\n",
        "    return macd, signal_, hist\n",
        "\n",
        "def _annualised_vol(ret, window):\n",
        "    vol = ret.rolling(window, min_periods=1).std()\n",
        "    return (vol * np.sqrt(252)).fillna(0.0)   # daily annualisation; acceptable default\n",
        "\n",
        "# ---------- 7) Per-asset feature engineering (no global NaN drops) ----------\n",
        "def engineer_for_asset(df_in: pd.DataFrame, price_col: str, prefix: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build engineered features for a single asset.\n",
        "    - Uses min_periods=1 to keep full history.\n",
        "    - Returns a DataFrame indexed by Date with prefixed column names.\n",
        "    \"\"\"\n",
        "    px = df_in[[price_col]].rename(columns={price_col: \"close\"}).copy()\n",
        "\n",
        "    # Basic returns\n",
        "    px[\"ret1\"]   = _safe_pct_change(px[\"close\"], 1)\n",
        "    px[\"ret5\"]   = _safe_pct_change(px[\"close\"], 5)\n",
        "    px[\"ret21\"]  = _safe_pct_change(px[\"close\"], 21)\n",
        "\n",
        "    # Moving-average z-scores (scale-invariant)\n",
        "    for w in [5, 10, 20, 50, 100, 200]:\n",
        "        ma  = px[\"close\"].rolling(w, min_periods=1).mean()\n",
        "        std = px[\"close\"].rolling(w, min_periods=1).std().replace(0, np.nan)\n",
        "        z   = ((px[\"close\"] - ma) / std).replace([np.inf, -np.inf], np.nan).fillna(0.0).clip(-10, 10)\n",
        "        px[f\"ma{w}_z\"] = z\n",
        "\n",
        "    # EMA relative gaps\n",
        "    for w in [10, 20, 50]:\n",
        "        ema = px[\"close\"].ewm(span=w, adjust=False, min_periods=1).mean()\n",
        "        px[f\"ema{w}_gap\"] = ((px[\"close\"] - ema) / ema.replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0.0).clip(-10, 10)\n",
        "\n",
        "    # Volatility\n",
        "    for w in [10, 20, 60, 120]:\n",
        "        px[f\"vol{w}\"] = _annualised_vol(px[\"ret1\"], w)\n",
        "\n",
        "    # RSI / Bollinger / MACD\n",
        "    px[\"rsi14\"] = _rsi(px[\"close\"], 14)\n",
        "    _, _, _, bb_w = _bollinger(px[\"close\"], 20, 2.0)\n",
        "    px[\"bb20_width\"] = bb_w\n",
        "    macd, sig, hist = _macd(px[\"close\"], 12, 26, 9)\n",
        "    px[\"macd\"] = macd; px[\"macd_signal\"] = sig; px[\"macd_hist\"] = hist\n",
        "\n",
        "    # Return only features (no raw close)\n",
        "    feat = px.drop(columns=[\"close\"]).copy()\n",
        "    feat.columns = [f\"{prefix}__{c}\" for c in feat.columns]\n",
        "    return feat\n",
        "\n",
        "# Build per-asset feature frames\n",
        "feat_frames = []\n",
        "for a in ASSETS:\n",
        "    lbl = a[\"label\"].lower()\n",
        "    feat_frames.append(engineer_for_asset(df0, a[\"price_col\"], prefix=lbl))\n",
        "\n",
        "# ---------- 8) Join back to RAW (left joins preserve full index) ----------\n",
        "df_eng = df0.copy()\n",
        "for f in feat_frames:\n",
        "    df_eng = df_eng.join(f, how=\"left\")\n",
        "\n",
        "# Identify engineered columns we added\n",
        "added_cols = []\n",
        "for f in feat_frames:\n",
        "    added_cols.extend(list(f.columns))\n",
        "added_cols = list(dict.fromkeys(added_cols))  # unique & ordered\n",
        "\n",
        "# Sanitise engineered features only (no row drops)\n",
        "df_eng[added_cols] = (\n",
        "    df_eng[added_cols]\n",
        "      .replace([np.inf, -np.inf], np.nan)\n",
        "      .fillna(0.0)\n",
        "      .clip(lower=-10.0, upper=10.0)\n",
        ")\n",
        "\n",
        "# ---------- 9) Diagnostics ----------\n",
        "def diag(df: pd.DataFrame, name: str):\n",
        "    print(f\"[{name}] rows={len(df)} | {df.index.min().date()} → {df.index.max().date()}\")\n",
        "    print(\"rows with any NaN:\", int(df.isna().any(axis=1).sum()))\n",
        "\n",
        "diag(df0,   \"RAW (input)\")\n",
        "diag(df_eng, \"ENG (post-join + sanitise)\")\n",
        "\n",
        "# Show top offenders if any engineered NaN remain (should be zero)\n",
        "left_na = df_eng[added_cols].isna().sum().sort_values(ascending=False)\n",
        "if len(left_na) and left_na.iloc[0] > 0:\n",
        "    print(\"Engineered columns with remaining NaN (top 10):\")\n",
        "    print(left_na.head(10))\n",
        "\n",
        "# ---------- 10) Save outputs ----------\n",
        "df_eng.reset_index().to_parquet(OUT_PARQUET, index=False)\n",
        "df_eng.reset_index().to_csv(OUT_CSV, index=False)\n",
        "\n",
        "print(\"\\nSaved engineered dataset:\")\n",
        "print(\"  \", OUT_PARQUET)\n",
        "print(\"  \", OUT_CSV)\n"
      ],
      "metadata": {
        "id": "PvtfUs9sK1bo",
        "outputId": "cabc3791-83dd-456b-d1d3-c88fb3deeccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PROJECT_DIR: /content/drive/MyDrive/gt-markets\n",
            "DATA_DIR:    /content/drive/MyDrive/gt-markets/data/processed\n",
            "Using RAW_FILE: merged_financial_trends_data_2025-09-07.csv\n",
            "Filling NaN in trend cols with 0 (first 10 shown): ['entrepreneurial_trend', 'cryptocurrency_trend']\n",
            "[RAW (input)] rows=2609 | 2015-09-08 → 2025-09-05\n",
            "rows with any NaN: 1496\n",
            "[ENG (post-join + sanitise)] rows=2609 | 2015-09-08 → 2025-09-05\n",
            "rows with any NaN: 1496\n",
            "\n",
            "Saved engineered dataset:\n",
            "   /content/drive/MyDrive/gt-markets/data/processed/merged_financial_trends_engineered_2025-09-07.parquet\n",
            "   /content/drive/MyDrive/gt-markets/data/processed/merged_financial_trends_engineered_2025-09-07.csv\n"
          ]
        }
      ]
    }
  ]
}